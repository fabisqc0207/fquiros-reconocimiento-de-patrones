{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de Patrones\n",
    "\n",
    "## Investigación III\n",
    "\n",
    "### Auto ML: contexto y ejemplos\n",
    "\n",
    "#### Estudiante: Fabricio Quirós Corella"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Resumen\n",
    "\n",
    "El presente consiste en un abordaje de los particularidades y una estudio general y superficial de AutoML, cómo se emplea en ML, así como su utilidad en este campo. Igualmente, abarca herramientas que consideran AutoML, como lo son Auto-Sklearn, TPOT y Google Cloud AutoML, donde se ejemplifican mediante el uso de un par de ejemplo prácticos sencillos, para así darle sentido al uso de AutoML dentro del área del Reconocimiento de Patrones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AutoML\n",
    "\n",
    "Es un conjunto de herramientas que automatizan operaciones relativas al proceso general de Machine Learning (ML), tales como el preprocesado, selección del algoritmo, modelado iterativo, ajuste de hiperparámetros y el evaluación del modelo resultante, donde su objetivo consiste en encontrar de manera automática la mejor implementación de ML para un set de datos en particular mediante la evaluación de miles de posibilidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Herramientas disponibles\n",
    "\n",
    "Entre las principales herramientas, cabe mencionar las siguientes, donde, más adelante, se implementan un par ejemplos básicos  basados en dos librerías de Python, cuyo código es abierto, esto para AutoML. A continuación, se enlistan dichos aportes:\n",
    "\n",
    "* **Auto-Sklearn:** construida sobre *scikit-learn*, capaz de efectuar automáticamente la selección del algoritmo y el ajuste de hiperparámetros, mediante optimización Bayesiana.\n",
    "* **TPOT (Tree-based Pipeline Optimization):** fundamentada igualmente en la API de *scikit-learn*, la cual genera y optimiza *pipelines* de ML empleando programación genética; bajo este contexto, consiste en que los modelos computados son codificados en \"genes\", los cuales van evolucionando conforme se aplica el algoritmo en cuestión.\n",
    "* **Google AutoML:** permite el uso de AutoML para la construcción automática de modelos de aprendizaje a través de las facilidades de ML que ofrece Google. La siguiente publicación de Medium amplia en dicho tema: [link]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aplicación\n",
    "\n",
    "El concepto de AutoML resulta de suma importantancia y utilidad en el campo del reconocimiento de patrones, puesto que, en dado caso un algoritmo de ML no funciona lo suficientemente bien o ni siquiera funciona, el proceso de seleccionar y refinar dicho método se convierte en iterativo, donde la construcción de un modelo, a partir de numerosos modelos de ML, empleando una gran cantidad de algoritmos y diversas configuraciones de hiperparámetros, puede ser automatizada, así como la comparación de los resultados correspondientes en términos de rendimiento y precisión, facilitando evidenmente las tareas del científico de datos y las decisiones sobre un modelo de aprendizaje en específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ejemplo práctico: auto-sklearn\n",
    "\n",
    "La presente sección incluye la implementación de las tareas de Clasificación y de Regresión, disponibles en la librería de AutoML conocida como ***auto-sklearn***, donde se muestran resultados de los modelos de ML obtenido de forma automática, así como el puntaje de las predicciones respectivas. Inicialmente, se importan librerías útiles, a lo largo de los ejemplos adjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scikit-learn utilities\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Clasificación\n",
    "\n",
    "\n",
    "#### 4.1.1. Crosvalidación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Importar las librerías correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import auto-sklearn classification\n",
    "import autosklearn.classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Cargar el set de datos disponibles en *scikit-learn* de las imágenes de los dígitos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sklearn.datasets.load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Preparar el set de pruebas y de entrenamiento, tanto para la salida (***targets***) y para la entrada (***features***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Implementar la tarea de AutoML, relativa a la Clasificación, considerando una estrategia de remuestreo de Cros-validación, donde se particiona el set de datos en una cantidad de *folds*, generalmente 5, con el propósito de mejorar su capacidad de generalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a auto-sklearn classifier object\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    # Time limit in seconds for the search of appropriate models.\n",
    "    time_left_for_this_task=120,\n",
    "    # Time limit for a single call to the machine learning model.\n",
    "    per_run_time_limit=30,\n",
    "    tmp_folder='/tmp/autoslearn_cv_example_tmp',\n",
    "    output_folder='/tmp/autosklearn_cv_example_out',\n",
    "    delete_tmp_folder_after_terminate=True,\n",
    "    resampling_strategy='cv',\n",
    "    resampling_strategy_arguments={'folds': 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Ajustar los modelos de ML a los sets de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit() changes the data in place, but refit needs the original data. We\n",
    "# therefore copy the data. In practice, one should reload the data\n",
    "automl.fit(X_train.copy(), y_train.copy(), dataset_name='digits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Aplicar un reajuste al modelo con base en el set de entrenamiento, necesario al emplear Cros-validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During fit(), models are fit on individual cross-validation folds. To use\n",
    "# all available data, we call refit() which trains all models in the\n",
    "# final ensemble on the whole dataset.\n",
    "automl.refit(X_train.copy(), y_train.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Desplegar información asociada al proceso de definición del modelo de aprendizaje automático, como el nombre del dataset empleado, así como su métrica y el mejor puntaje de validación, así como la cantidad de corridas existosas y no-exitosas del algoritmo durante el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics of the training result\n",
    "print(automl.sprint_statistics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** Ensamble final encontrado por la librería, correspondiente a los modelos de aprendizaje computados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the final model\n",
    "print(automl.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** Puntaje de la predicción de las clases a partir del set de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict the classes for a feature set.\n",
    "predictions = automl.predict(X_test)\n",
    "print(\"AutoSklearn Classifier (k-fold CV) - Accuracy score:\", sklearn.metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2. *Holdout*\n",
    "\n",
    "Técnica de validación que consiste inicialmente en particionar el set de datos en uno de entrenamiento (**TRAIN**), de validación (**VALIDACIÓN**) y pruebas (**TEST**), donde se entrena un modelo y se somete al set de validación, produciendo así una métrica de validación. Nuevamente, se entrena dicho modelo, y posteriormente, este es alimentado con el set de prueba, produciendo en esta ocasión, una métrica de pruebas, favoreciendo a la comparación entre modelos. \n",
    "\n",
    "**1.** Ahora, actualizar la tarea de Clasificación de AutoML, empleando esta vez el método de Validación descrito anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a auto-sklearn classifier object\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    # Time limit in seconds for the search of appropriate models.\n",
    "    time_left_for_this_task=120,\n",
    "    # Time limit for a single call to the machine learning model.\n",
    "    per_run_time_limit=30,\n",
    "    tmp_folder='/tmp/autosklearn_holdout_example_tmp',\n",
    "    output_folder='/tmp/autosklearn_holdout_example_out',\n",
    "    delete_tmp_folder_after_terminate=True,\n",
    "    # 'holdout' with 'train_size'=0.67 is the default argument setting\n",
    "    # for AutoSklearnClassifier. It is explicitly specified in this example\n",
    "    # for demonstrational purpose.\n",
    "    resampling_strategy='holdout',\n",
    "    resampling_strategy_arguments={'train_size': 0.67}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Ajustar el modelo actualizado al set de entrenamiento nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the auto-sklearn model on the training data\n",
    "automl.fit(X_train, y_train, dataset_name='digits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Mostrar estadísticas asociadas al proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics of the training result\n",
    "print(automl.sprint_statistics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Desplegar de resultados de la representación final, encontrada por *auto-sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a representation of the final ensemble found by auto-sklearn\n",
    "print(automl.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Predicción final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict the classes for a feature set.\n",
    "predictions = automl.predict(X_test)\n",
    "print(\" AutoSklearn Classifier (Holdout) - Accuracy score:\", sklearn.metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Importar la librería de Regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import auto-sklearn regression\n",
    "import autosklearn.regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Una vez importadas las librerías necesarias, se carga el dataset de los precios de las casas de Boston (ejemplo de Regresión: predecir un número continuo, dentro de un rango establecido)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sklearn.datasets.load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Definición de aquella variable que describe el tipo de los atributos empleados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = (['numerical'] * 3) + ['categorical'] + (['numerical'] * 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Nuevamente, preparar tanto el set de pruebas como el de entrenamiento, esto para ***features*** de entrada y ***targets*** de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Generar el modelo simple de Regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a auto-sklearn regressor object\n",
    "automl = autosklearn.regression.AutoSklearnRegressor(\n",
    "    # Time limit in seconds for the search of appropriate models.\n",
    "    time_left_for_this_task=120,\n",
    "    # Time limit for a single call to the machine learning model.\n",
    "    per_run_time_limit=30,\n",
    "    tmp_folder='/tmp/autosklearn_regression_example_tmp',\n",
    "    output_folder='/tmp/autosklearn_regression_example_out',\n",
    "    delete_tmp_folder_after_terminate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Ajustar el modelo definido al set de entrenamiento, dependiendo del tipo de atributos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the auto-sklearn model on the training data\n",
    "automl.fit(X_train, y_train, dataset_name='boston', feat_type=feature_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Resultados asociados al proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics of the training result\n",
    "print(automl.sprint_statistics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** Obtener la representación final del ensamble de regresión encontrado por *auto-sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a representation of the final ensemble found by auto-sklearn\n",
    "print(automl.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** Predicción final y despliegue del valor asociado al coeficiente de regresión asociado al método considerado por **auto-sklearn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict the classes for a feature set.\n",
    "predictions = automl.predict(X_test)\n",
    "print(\" AutoSklearn Regressor - R2 score:\", sklearn.metrics.r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ejemplo práctico: TPOT\n",
    "\n",
    "Al igual que la sección anterior, se realiza la demostración de ejemplos básicos de Clasificación y Regresión usando la librería de AutoML conocida como **TPOT (Tree-based Pipeline Optimization)**, la cual, al igual que **auto-sklearn**, pretende encontrar automaticamente el modelo que mejor se ajuste al set de datos dado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Incluir la librería de Clasificación TPOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tpot classifier\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Cargar nuevamente el set de datos relativos a los dígitos númericos, empleado en los ejemplos anteriores de Clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sklearn.datasets.load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Ejecutar la división del set de datos en clases a predecir (*targets*) y atributos (*features*) a evaluar, asociados tanto al entrenamiento como a las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Crear la instancia de la tarea de Clasificación de la librería TPOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tpot classifier object\n",
    "automl = TPOTClassifier(\n",
    "    generations=5,\n",
    "    # By default, the number of offspring is equal to the number of population size\n",
    "    population_size=20, offspring_size=None,\n",
    "    # Recomendation: keep both default parameters unless how the mutation rate affects GP algorithms is understood\n",
    "    mutation_rate=0.9, crossover_rate=0.1,\n",
    "    scoring='accuracy', cv=5, # k-fold CrossValidation (k=5)\n",
    "    # Setting n_jobs=-1 will use as many cores as available on the computer. \n",
    "    subsample=1.0, n_jobs=1,\n",
    "    # Help TPOT from wasting time on evaluating time-consuming pipelines.\n",
    "    max_time_mins=None, max_eval_time_mins=5,\n",
    "    # make sure that TPOT will give you the same results each time \n",
    "    # you run it against the same data set with that seed\n",
    "    random_state=None, config_dict=None,\n",
    "    warm_start=False, memory=None,\n",
    "    use_dask=False, periodic_checkpoint_folder=None,\n",
    "    early_stop=None, verbosity=0,\n",
    "    disable_update_check=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Ajustar el modelo TPOT al set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the tpot model on the training data\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Obtener el mejor *pipeline* descubierto por TPOT durante el proceso de optimización, ajustado al set completo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the final model\n",
    "print(automl.fitted_pipeline_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Emplear el modelo optimizado mediante AutoML para realizar predicciones de las clases correspondientes al set de datos de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optimized pipeline to predict the classes for a feature set.\n",
    "predictions = automl.predict(X_test)\n",
    "print(\"TPOT Regressor - Sci-kit Learn Accuracy score:\", sklearn.metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "# Optimized pipeline's score on the given testing data (Same result as above)\n",
    "print(\"TPOT Regressor - TPOT Accuracy score:\", automl.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Incluir la librería de Regresión TPOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tpot regressor\n",
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Cargar una vez más el *dataset* de los precios de las casas de Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sklearn.datasets.load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Partición del set de datos, tanto para sus atributos como para sus clases, en un conjunto asociado al entrenamiento y otro las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Crear la instancia de la tarea de Regresión TPOT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tpot object (default parameters are shown)\n",
    "automl = TPOTRegressor(\n",
    "    generations=5, \n",
    "    population_size=20, offspring_size=None,\n",
    "    mutation_rate=0.9, crossover_rate=0.1,\n",
    "    # neg version of mean squared error and related metrics so \n",
    "    # TPOT will minimize (instead of maximize) the metric \n",
    "    # (scoring default='neg_mean_squared_error')\n",
    "    scoring='r2', cv=5,\n",
    "    subsample=1.0, n_jobs=1,\n",
    "    # Help TPOT from wasting time on evaluating time-consuming pipelines.\n",
    "    max_time_mins=None, max_eval_time_mins=5,\n",
    "    # make sure that TPOT will give you the same results each time \n",
    "    # you run it against the same data set with that seed\n",
    "    random_state=None, config_dict=None,\n",
    "    warm_start=False, memory=None,\n",
    "    use_dask=False, periodic_checkpoint_folder=None,\n",
    "    early_stop=None, verbosity=0,\n",
    "    disable_update_check=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Ajustar el modelo TPOT computado al *dataset* de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the tpot model on the training data\n",
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Desplegar el *pipeline* óptimo encontrado durante el proceso de optimización, ajustado al set completo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the final model\n",
    "print(automl.fitted_pipeline_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Someter el modelo optimizado mediante AutoML para realizar predicciones de las clases correspondientes al *dataset* de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optimized pipeline to predict the classes for a feature set.\n",
    "predictions = automl.predict(X_test)\n",
    "print(\"TPOT Regressor - Sci-kit Learn R2 score:\", sklearn.metrics.r2_score(y_test, predictions))\n",
    "\n",
    "# Optimized pipeline's score on the given testing data (Same result as above)\n",
    "print(\"TPOT Regressor - TPOT R2 score:\", automl.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Referencias\n",
    "\n",
    "* https://automl.github.io/auto-sklearn/stable/#\n",
    "\n",
    "\n",
    "* https://automl.github.io/auto-sklearn/stable/api.html\n",
    "\n",
    "\n",
    "* https://epistasislab.github.io/tpot/\n",
    "\n",
    "\n",
    "* https://github.com/yu-iskw/auto-sklearn-examples\n",
    "\n",
    "\n",
    "* https://towardsdatascience.com/automated-machine-learning-on-the-cloud-in-python-47cf568859f\n",
    "\n",
    "\n",
    "* https://www.automl.org/\n",
    "\n",
    "\n",
    "* https://www.kdnuggets.com/2017/01/current-state-automated-machine-learning.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
